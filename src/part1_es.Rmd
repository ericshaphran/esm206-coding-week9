---
title: 'Part 1: Multiple Linear Regression'
author: "Eric Shaphran"
date: "12/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(palmerpenguins)
library(GGally)
library(stargazer)
```


```{r}
penguins %>%
  ggpairs()
```

```{r}
penguins %>%
  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %>%
  ggpairs(aes(color = species))
```

## Build a few different models

```{r}
lm1 <- lm(body_mass_g ~ flipper_length_mm + species, data = penguins)
lm1

lm2 <- lm(body_mass_g ~ flipper_length_mm + species + sex, data = penguins)
lm2

lm3 <- lm(body_mass_g ~ flipper_length_mm + species + sex + bill_length_mm, data = penguins)
lm3

lm4 <- lm(body_mass_g ~ flipper_length_mm + species + sex + bill_length_mm + island, data = penguins)
lm4
```

## Find the AIC value for each model

```{r}
AIC(lm1)
AIC(lm2)
AIC(lm3)
AIC(lm4)
# lowest AIC value indicates best balance of model fit and model complexity
```

AIC should only be part of the way we choose models. We need to think about what we already know about models: what do we understand conceptually and what does the research already show (lit reviews)

## Use stargazer package for a table with multiple model outputs

```{r, results = 'asis'}
stargazer(lm1, lm3, lm4, type = "html")
```

